# E2E Test Workflow for falco-plugin-nginx
# Issue #3: E2E test workflow implementation
#
# This workflow runs E2E tests to validate the Falco nginx plugin
# can detect security threats in nginx access logs.
#
# Design Decisions (from ISSUE_774_REQUIREMENTS.md):
# - DD-001: Single VM test environment (ubuntu-24.04)
# - DD-002: k6 + Python (batch_analyzer.py)
# - DD-003: Falco file output (/var/log/falco/falco.log)
# - DD-004: Allure Report + GitHub Artifacts
# - DD-005: 500ms pattern send interval
# - DD-006: Single port (80) for all categories
# - DD-012: Plugin-only mode (--disable-source syscall)

name: E2E Tests

on:
  workflow_dispatch:
    inputs:
      debug_enabled:
        description: 'Enable debug logging'
        required: false
        default: 'false'
        type: boolean
  push:
    branches:
      - main
    paths:
      - 'plugin/**'
      - 'rules/**'
      - 'e2e/**'
      - '.github/workflows/e2e-test.yml'
  pull_request:
    branches:
      - main
    paths:
      - 'plugin/**'
      - 'rules/**'
      - 'e2e/**'
      - '.github/workflows/e2e-test.yml'

# Required for GitHub Pages deployment
permissions:
  contents: write
  pages: write
  id-token: write

env:
  # Target configuration
  TARGET_IP: localhost
  TARGET_PORT: '80'
  # Falco configuration
  FALCO_LOG_PATH: /var/log/falco/falco.log
  NGINX_LOG_PATH: /var/log/nginx/access.log
  # Batch processing (Issue #8: reduced from 60s to 5s)
  BATCH_WAIT_TIME: '5'
  # Detection threshold
  MIN_DETECTION_RATE: '0.95'

jobs:
  e2e-test:
    name: E2E Security Tests
    runs-on: ubuntu-24.04
    timeout-minutes: 30

    steps:
      # ========================================
      # 1. Setup
      # ========================================
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install -r e2e/allure/requirements.txt

      # ========================================
      # 2. Install k6 (DD-007)
      # ========================================
      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg \
            --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" \
            | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install -y k6
          k6 version

      # ========================================
      # 3. Install nginx (DD-006)
      # ========================================
      - name: Install and configure nginx
        run: |
          sudo apt-get install -y nginx

          # Configure nginx with custom log format for E2E testing
          # Include X-Test-ID, X-Category, X-Pattern-ID headers in access log
          sudo tee /etc/nginx/nginx.conf > /dev/null << 'EOF'
          user www-data;
          worker_processes auto;
          pid /run/nginx.pid;
          include /etc/nginx/modules-enabled/*.conf;

          events {
              worker_connections 768;
          }

          http {
              sendfile on;
              tcp_nopush on;
              types_hash_max_size 2048;
              include /etc/nginx/mime.types;
              default_type application/octet-stream;

              # Custom log format with test headers for E2E testing
              # Pattern #A320: Include X-Test-ID, X-Category, X-Pattern-ID in access log
              log_format e2e '$remote_addr - $remote_user [$time_local] "$request" '
                             '$status $body_bytes_sent "$http_referer" '
                             '"$http_user_agent" '
                             'x_test_id=$http_x_test_id '
                             'x_category=$http_x_category '
                             'x_pattern_id=$http_x_pattern_id';

              access_log /var/log/nginx/access.log e2e;
              error_log /var/log/nginx/error.log;

              gzip on;

              server {
                  listen 80 default_server;
                  listen [::]:80 default_server;

                  root /var/www/html;
                  index index.html;

                  server_name _;

                  location / {
                      try_files $uri $uri/ =404;
                  }
              }
          }
          EOF

          # Create simple index page
          echo "<html><body><h1>E2E Test Server</h1></body></html>" | sudo tee /var/www/html/index.html

          # Verify nginx config
          sudo nginx -t

          # Start nginx
          sudo systemctl restart nginx
          sudo systemctl status nginx

          # Verify nginx is running
          curl -s http://localhost/ | head -5

      # ========================================
      # 4. Install Falco (DD-009)
      # ========================================
      - name: Install Falco
        run: |
          # Add Falco repository
          curl -fsSL https://falco.org/repo/falcosecurity-packages.asc | \
            sudo gpg --dearmor -o /usr/share/keyrings/falco-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/falco-archive-keyring.gpg] https://download.falco.org/packages/deb stable main" | \
            sudo tee /etc/apt/sources.list.d/falcosecurity.list
          sudo apt-get update
          sudo DEBIAN_FRONTEND=noninteractive apt-get install -y falco

          # Verify installation
          falco --version

      # ========================================
      # 5. Configure Falco plugin (DD-012)
      # ========================================
      - name: Download and configure Falco plugin
        run: |
          # Create directories
          sudo mkdir -p /usr/share/falco/plugins
          sudo mkdir -p /etc/falco/rules.d
          sudo mkdir -p /etc/falco/config.d
          sudo mkdir -p /var/log/falco
          sudo touch /var/log/falco/falco.log
          sudo chmod 644 /var/log/falco/falco.log

          # Download plugin binary from latest release
          # Note: Use GITHUB_TOKEN to avoid API rate limiting (60 req/hour unauthenticated vs 5000 req/hour authenticated)
          # Use endswith(".so") to exclude .sha256 checksum files
          PLUGIN_URL=$(curl -s -H "Authorization: token ${{ secrets.GITHUB_TOKEN }}" \
            https://api.github.com/repos/takaosgb3/falco-plugin-nginx/releases/latest | \
            jq -r '.assets[] | select(.name | endswith("linux-amd64.so")) | .browser_download_url')

          if [ -z "$PLUGIN_URL" ] || [ "$PLUGIN_URL" == "null" ]; then
            echo "::error::Failed to find plugin binary in latest release"
            exit 1
          fi

          echo "Downloading plugin from: $PLUGIN_URL"
          sudo curl -L -o /usr/share/falco/plugins/libfalco-nginx-plugin.so "$PLUGIN_URL"
          sudo chmod 755 /usr/share/falco/plugins/libfalco-nginx-plugin.so

          # Verify plugin
          file /usr/share/falco/plugins/libfalco-nginx-plugin.so

          # Copy rules file
          sudo cp rules/nginx_rules.yaml /etc/falco/rules.d/

          # Create plugin configuration
          sudo tee /etc/falco/config.d/nginx-plugin.yaml > /dev/null << 'EOF'
          # nginx plugin configuration for E2E testing

          # Load nginx plugin only
          load_plugins:
            - nginx

          # Plugin settings
          plugins:
            - name: nginx
              library_path: /usr/share/falco/plugins/libfalco-nginx-plugin.so
              init_config:
                log_paths:
                  - /var/log/nginx/access.log

          # Rules files (individual paths, not directory - Issue #643)
          rules_files:
            - /etc/falco/rules.d/nginx_rules.yaml

          # File output for batch_analyzer.py (DD-003)
          file_output:
            enabled: true
            filename: /var/log/falco/falco.log
            keep_alive: false

          # stdout output for debugging
          stdout_output:
            enabled: true
          EOF

          echo "Falco plugin configured successfully"

      # ========================================
      # 6. Start Falco (DD-012: plugin-only mode)
      # ========================================
      - name: Start Falco in plugin-only mode
        run: |
          # Start Falco in background with plugin-only mode
          sudo /usr/bin/falco \
            -c /etc/falco/falco.yaml \
            --disable-source syscall \
            2>&1 | tee /tmp/falco-startup.log &

          # Wait for Falco to initialize with timeout (more robust than fixed sleep)
          echo "Waiting for Falco to initialize..."
          FALCO_STARTED=false
          for i in $(seq 1 30); do
            if grep -q "Starting" /tmp/falco-startup.log 2>/dev/null || \
               grep -q "nginx" /tmp/falco-startup.log 2>/dev/null; then
              echo "Falco started successfully after ${i} seconds"
              FALCO_STARTED=true
              break
            fi
            sleep 1
          done

          # Verify Falco is running
          if ! $FALCO_STARTED; then
            echo "::warning::Falco startup marker not found in logs, checking process..."
          fi

          if pgrep -x falco > /dev/null; then
            echo "Falco process is running"
          else
            echo "::error::Falco failed to start"
            cat /tmp/falco-startup.log
            exit 1
          fi

          # Check for plugin load
          if grep -q "nginx" /tmp/falco-startup.log; then
            echo "nginx plugin loaded successfully"
          else
            echo "::warning::nginx plugin load message not found in startup log"
          fi

      # ========================================
      # 7. Run k6 E2E tests (DD-002, DD-005)
      # ========================================
      - name: Run k6 E2E tests
        run: |
          # Create results directory
          mkdir -p e2e/results

          # Run k6 tests and capture output for test_id extraction
          # Note: k6's handleSummary cannot access VU-level data (testIdRecords array)
          # So we extract test_ids from console log output instead
          cd e2e
          k6 run \
            -e TARGET_IP=${{ env.TARGET_IP }} \
            -e TARGET_PORT=${{ env.TARGET_PORT }} \
            k6/main.js 2>&1 | tee results/k6-output.log

          # Extract test_ids from k6 console output (Pattern #A319 fix)
          # Format: time="..." level=info msg="[SENT] PATTERN_ID: test_id=TEST_ID" source=console
          echo "Extracting test_ids from k6 output..."
          CURRENT_TIMESTAMP=$(date +%s)000
          grep '\[SENT\]' results/k6-output.log | \
            sed 's/.*\[SENT\] \([^:]*\): test_id=\([^"]*\)".*/{"pattern_id":"\1","test_id":"\2","sent_at":'"$CURRENT_TIMESTAMP"'}/' | \
            jq -s '.' > results/test_ids.json || echo "[]" > results/test_ids.json

          # Show results summary
          echo "=== Test IDs Summary ==="
          if [ -f results/test_ids.json ]; then
            jq '. | length' results/test_ids.json
            echo "test IDs generated"
          fi

          if [ -f results/summary.json ]; then
            echo "=== k6 Summary ==="
            jq '.test_results' results/summary.json
          fi

      # ========================================
      # 8. Wait for Falco processing (NFR-001-3)
      # ========================================
      - name: Wait for Falco processing
        run: |
          echo "Waiting ${BATCH_WAIT_TIME} seconds for Falco to process all events..."
          sleep ${{ env.BATCH_WAIT_TIME }}

          # Show Falco log stats
          if [ -f "${{ env.FALCO_LOG_PATH }}" ]; then
            echo "=== Falco Log Stats ==="
            echo "Total lines: $(wc -l < ${{ env.FALCO_LOG_PATH }})"
            echo "Detections with test_id: $(grep -c 'test_id=' ${{ env.FALCO_LOG_PATH }} || echo 0)"
          else
            echo "Warning: Falco log file not found"
          fi

      # ========================================
      # 9. Run batch analyzer (FR-004)
      # ========================================
      - name: Analyze test results
        run: |
          cd e2e

          # Copy logs for analysis
          sudo cp ${{ env.FALCO_LOG_PATH }} results/falco.log || true
          sudo cp ${{ env.NGINX_LOG_PATH }} results/nginx-access.log || true
          sudo chmod 644 results/*.log || true

          # Run batch analyzer
          python scripts/batch_analyzer.py \
            --patterns patterns/ \
            --falco-log results/falco.log \
            --test-ids results/test_ids.json \
            --output results/test-results.json \
            --summary-output results/analysis-summary.json \
            ${{ inputs.debug_enabled == 'true' && '--verbose' || '' }}

          # Show analysis summary
          if [ -f results/analysis-summary.json ]; then
            echo "=== Analysis Summary ==="
            cat results/analysis-summary.json | jq '.'
          fi

      # ========================================
      # 10. Download Allure History (DD-013)
      # ========================================
      - name: Download previous Allure history
        id: download_history
        run: |
          echo "=========================================="
          echo "Downloading Previous Allure History (DD-013)"
          echo "=========================================="

          # Fetch gh-pages branch
          git fetch origin gh-pages:gh-pages 2>/dev/null || {
            echo "gh-pages branch not found, starting fresh"
            echo "history_available=false" >> $GITHUB_OUTPUT
            exit 0
          }

          # Find latest run number from redirect
          LATEST_RUN=$(git show gh-pages:e2e-report/latest/index.html 2>/dev/null | \
            grep -oP 'url=\.\./\K[0-9]+' || echo "")

          if [ -z "$LATEST_RUN" ]; then
            echo "No previous run found in latest redirect"
            echo "history_available=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "Found previous run: $LATEST_RUN"

          # Create history directory
          mkdir -p e2e/allure-results/history

          # Download history files
          HISTORY_FOUND=false

          if git show "gh-pages:e2e-report/$LATEST_RUN/history/history.json" \
            > e2e/allure-results/history/history.json 2>/dev/null; then
            echo "Downloaded history.json"
            HISTORY_FOUND=true
          fi

          if git show "gh-pages:e2e-report/$LATEST_RUN/history/history-trend.json" \
            > e2e/allure-results/history/history-trend.json 2>/dev/null; then
            echo "Downloaded history-trend.json"
          fi

          # Additional history files (categories, retry, duration trends)
          for file in categories.json categories-trend.json duration-trend.json retry-trend.json; do
            git show "gh-pages:e2e-report/$LATEST_RUN/history/$file" \
              > e2e/allure-results/history/$file 2>/dev/null || true
          done

          # Download Rule Mapping Trend history (Issue #68)
          if git show "gh-pages:e2e-report/$LATEST_RUN/widgets/rule-mapping-trend-history.json" \
            > e2e/allure-results/history/rule-mapping-trend-history.json 2>/dev/null; then
            echo "Downloaded rule-mapping-trend-history.json"
          else
            echo "::notice::Rule Mapping Trend history not found in run $LATEST_RUN (expected for first run or after migration)"
          fi

          if [ "$HISTORY_FOUND" = true ]; then
            echo "History files downloaded successfully"
            echo "history_available=true" >> $GITHUB_OUTPUT
            ls -la e2e/allure-results/history/
          else
            echo "No history files found in previous run"
            echo "history_available=false" >> $GITHUB_OUTPUT
          fi

      # ========================================
      # 10. Generate Rule Mapping Trend HTML (Issue #68)
      # Note: Issue #59 script (generate_rule_mapping_trend.py) removed in Issue #70
      #       It caused duplicate entries in categories-trend.json by conflicting
      #       with Allure CLI's own history management.
      # ========================================
      - name: Generate Rule Mapping Trend HTML
        run: |
          echo "=========================================="
          echo "Generating Rule Mapping Trend HTML (Issue #68)"
          echo "=========================================="

          cd e2e

          # Ensure output directories exist
          mkdir -p allure-results/history
          mkdir -p allure-results/widgets

          # Generate Rule Mapping Trend HTML page with error checking
          if ! python scripts/generate_rule_mapping_trend_html.py \
            --test-results results/test-results.json \
            --run-number ${{ github.run_number }} \
            --report-url "https://takaosgb3.github.io/falco-plugin-nginx/e2e-report/${{ github.run_number }}/" \
            --history-input allure-results/history/rule-mapping-trend-history.json \
            --history-output allure-results/widgets/rule-mapping-trend-history.json \
            --html-output allure-results/widgets/rule-mapping-trend.html \
            --max-history 20; then
            echo "::error::Failed to generate Rule Mapping Trend HTML"
            exit 1
          fi

          # Verify outputs exist
          if [ ! -f allure-results/widgets/rule-mapping-trend.html ]; then
            echo "::error::Rule Mapping Trend HTML file was not created"
            exit 1
          fi

          if [ ! -f allure-results/widgets/rule-mapping-trend-history.json ]; then
            echo "::error::Rule Mapping Trend history JSON was not created"
            exit 1
          fi

          echo "Rule Mapping Trend HTML generated successfully"
          echo "HTML file size: $(wc -c < allure-results/widgets/rule-mapping-trend.html) bytes"

      # ========================================
      # 11. Generate Allure Report (DD-004, DD-010)
      # ========================================
      - name: Install Allure CLI
        run: |
          sudo apt-get install -y default-jre
          npm install -g allure-commandline

      - name: Generate Allure results
        run: |
          cd e2e

          # Ensure allure-results exists (may have history from previous step)
          mkdir -p allure-results/history

          # Create environment.properties for Allure Environment widget
          cat > allure-results/environment.properties << EOF
          Platform=ubuntu-24.04
          Falco.Version=$(falco --version 2>/dev/null | head -1 | awk '{print $NF}' || echo "unknown")
          Plugin=falco-plugin-nginx
          nginx.Version=$(nginx -v 2>&1 | awk -F/ '{print $NF}' || echo "unknown")
          k6.Version=$(k6 version 2>/dev/null | head -1 | awk '{print $NF}' || echo "unknown")
          Python.Version=$(python --version 2>&1 | awk '{print $2}')
          Test.Patterns=300
          Target.Host=${{ env.TARGET_IP }}:${{ env.TARGET_PORT }}
          EOF

          echo "Created environment.properties:"
          cat allure-results/environment.properties

          # Create executor.json for Allure Executors widget
          cat > allure-results/executor.json << EOF
          {
            "name": "GitHub Actions",
            "type": "github",
            "url": "https://github.com/${{ github.repository }}",
            "buildOrder": ${{ github.run_number }},
            "buildName": "E2E Tests #${{ github.run_number }}",
            "buildUrl": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
            "reportUrl": "https://takaosgb3.github.io/falco-plugin-nginx/e2e-report/${{ github.run_number }}/",
            "reportName": "Allure Report"
          }
          EOF

          echo "Created executor.json:"
          cat allure-results/executor.json

          # Run pytest to generate Allure results
          pytest allure/test_e2e_wrapper.py \
            --test-results=results/test-results.json \
            --logs-dir=results/ \
            --alluredir=allure-results \
            --tb=short \
            -v || true

          echo "Allure results generated"
          ls -la allure-results/

          # Show history status
          if [ -f allure-results/history/history.json ]; then
            echo "History included from previous run"
          fi

      - name: Generate Allure Report
        run: |
          cd e2e
          allure generate allure-results -o allure-report --clean

          echo "Allure report generated"
          ls -la allure-report/

          # Verify history was included in report
          if [ -d allure-report/history ]; then
            echo "Report includes history data"
            ls -la allure-report/history/
          fi

      # ========================================
      # 11b. Merge Rule Mapping data into Categories Trend (Issue #73, #76, #78)
      # IMPORTANT: This must run AFTER allure generate because:
      # 1. allure generate creates an entry for the current build
      # 2. Our script MERGES into that entry (no duplicates)
      # 3. We then copy the merged file to widgets/ for chart rendering
      # ========================================
      - name: Merge Rule Mapping into Categories Trend
        run: |
          echo "=========================================="
          echo "Merging Rule Mapping into Categories Trend (Issue #73, #76, #78)"
          echo "This runs AFTER allure generate to merge INTO Allure's entry"
          echo "=========================================="

          cd e2e

          # Check if categories-trend.json exists (generated by Allure CLI)
          if [ -f allure-report/history/categories-trend.json ]; then
            echo "Found Allure-generated categories-trend.json:"
            cat allure-report/history/categories-trend.json | head -50
          else
            echo "::warning::categories-trend.json not found, will create new"
          fi

          # Merge Rule Mapping data into allure-report/history/categories-trend.json
          # This merges INTO the entry created by Allure CLI (preventing duplicates)
          MERGE_OUTPUT=$(python scripts/generate_rule_mapping_trend.py \
            --test-results results/test-results.json \
            --run-number ${{ github.run_number }} \
            --report-url "https://takaosgb3.github.io/falco-plugin-nginx/e2e-report/${{ github.run_number }}/" \
            --history-input allure-report/history/categories-trend.json \
            --history-output allure-report/history/categories-trend.json \
            --max-history 20 \
            --verbose 2>&1) || {
            MERGE_EXIT_CODE=$?
            echo "::warning::Failed to merge Rule Mapping data (exit code: $MERGE_EXIT_CODE)"
            echo "Script output:"
            echo "$MERGE_OUTPUT"
            # Continue anyway since Categories Trend is non-critical
          }
          echo "$MERGE_OUTPUT"

          echo ""
          if [ -f allure-report/history/categories-trend.json ]; then
            echo "Updated categories-trend.json:"
            cat allure-report/history/categories-trend.json | head -50

            # Copy merged file to widgets/ so charts reflect the merged data
            # This is the key fix for Issue #78 - widgets/ is what the charts read from
            echo ""
            echo "Copying merged categories-trend.json to widgets/ for chart rendering..."
            cp allure-report/history/categories-trend.json allure-report/widgets/categories-trend.json
            echo "Widgets updated successfully"
          else
            echo "::warning::categories-trend.json does not exist after merge step"
          fi

      - name: Copy Rule Mapping Trend widgets to report
        run: |
          cd e2e

          # Copy Rule Mapping Trend widgets to report (Issue #68)
          if [ -d allure-results/widgets ]; then
            echo "Copying Rule Mapping Trend widgets to report..."
            mkdir -p allure-report/widgets
            cp -r allure-results/widgets/* allure-report/widgets/
            echo "Widgets copied:"
            ls -la allure-report/widgets/
          else
            echo "::warning::Rule Mapping Trend widgets directory not found. The trend HTML page will not be available in this report."
          fi

      # ========================================
      # 12. Upload artifacts (FR-005-3)
      # ========================================
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: e2e-test-results
          path: |
            e2e/results/
            e2e/allure-results/
          retention-days: 30

      - name: Upload Allure Report
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: allure-report
          path: e2e/allure-report/
          retention-days: 30

      # ========================================
      # 13. Deploy to GitHub Pages (DD-008)
      # ========================================
      - name: Deploy to GitHub Pages
        if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./e2e/allure-report
          destination_dir: e2e-report/${{ github.run_number }}
          keep_files: true

      # ========================================
      # 14. Update Latest Redirect (DD-013)
      # ========================================
      - name: Create latest redirect
        if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
        run: |
          echo "Creating latest redirect to run ${{ github.run_number }}"

          mkdir -p latest-redirect
          cat > latest-redirect/index.html << EOF
          <!DOCTYPE html>
          <html>
          <head>
            <meta http-equiv="refresh" content="0; url=../${{ github.run_number }}/" />
            <title>Redirecting to latest E2E report...</title>
          </head>
          <body>
            <p>Redirecting to <a href="../${{ github.run_number }}/">latest report (Run #${{ github.run_number }})</a>...</p>
          </body>
          </html>
          EOF

      - name: Deploy latest redirect
        if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./latest-redirect
          destination_dir: e2e-report/latest
          keep_files: false

      # ========================================
      # 14b. Create root index.html (Issue #10)
      # ========================================
      - name: Create root redirect
        if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
        run: |
          echo "Creating root redirect to latest E2E report"

          mkdir -p root-redirect
          cat > root-redirect/index.html << EOF
          <!DOCTYPE html>
          <html>
          <head>
            <meta http-equiv="refresh" content="0; url=e2e-report/${{ github.run_number }}/" />
            <title>Falco nginx Plugin - E2E Test Reports</title>
          </head>
          <body>
            <h1>Falco nginx Plugin - E2E Test Reports</h1>
            <p>Redirecting to <a href="e2e-report/${{ github.run_number }}/">latest report (Run #${{ github.run_number }})</a>...</p>
            <p><a href="e2e-report/latest/">Latest Report</a></p>
          </body>
          </html>
          EOF

      - name: Deploy root redirect
        if: github.ref == 'refs/heads/main' && github.event_name != 'pull_request'
        uses: peaceiris/actions-gh-pages@v4
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./root-redirect
          destination_dir: .
          keep_files: true

      # ========================================
      # 15. Job Summary
      # ========================================
      - name: Generate Job Summary
        if: always()
        run: |
          echo "## E2E Test Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ -f e2e/results/analysis-summary.json ]; then
            TOTAL=$(jq -r '.total_patterns' e2e/results/analysis-summary.json)
            DETECTED=$(jq -r '.detected' e2e/results/analysis-summary.json)
            RATE=$(jq -r '.detection_rate' e2e/results/analysis-summary.json)

            echo "| Metric | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Total Patterns | $TOTAL |" >> $GITHUB_STEP_SUMMARY
            echo "| Detected | $DETECTED |" >> $GITHUB_STEP_SUMMARY
            echo "| Detection Rate | $(echo "$RATE" | awk '{printf "%.1f%%", $1 * 100}') |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            if [ -f e2e/results/analysis-summary.json ]; then
              echo "### Latency" >> $GITHUB_STEP_SUMMARY
              echo "- Avg: $(jq -r '.latency.avg_ms' e2e/results/analysis-summary.json)ms" >> $GITHUB_STEP_SUMMARY
              echo "- Min: $(jq -r '.latency.min_ms' e2e/results/analysis-summary.json)ms" >> $GITHUB_STEP_SUMMARY
              echo "- Max: $(jq -r '.latency.max_ms' e2e/results/analysis-summary.json)ms" >> $GITHUB_STEP_SUMMARY
            fi
          else
            echo "Analysis summary not available" >> $GITHUB_STEP_SUMMARY
          fi

          # Issue #68: Add Rule Mapping statistics to summary
          # Note: Updated in Issue #70 to read from rule-mapping-trend-history.json
          #       instead of categories-trend.json (which is managed by Allure CLI)
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f e2e/allure-results/widgets/rule-mapping-trend-history.json ]; then
            echo "### Rule Mapping" >> $GITHUB_STEP_SUMMARY
            # Get the latest entry (sorted by buildOrder ascending, so last is newest)
            CURRENT_RUN=$(jq -r '.[-1]' e2e/allure-results/widgets/rule-mapping-trend-history.json)
            MATCH=$(echo "$CURRENT_RUN" | jq -r '.data["Rule Match"] // 0')
            MISMATCH=$(echo "$CURRENT_RUN" | jq -r '.data["Rule Mismatch"] // 0')
            EXPECTED_NOT=$(echo "$CURRENT_RUN" | jq -r '.data["Expected Not Detected"] // 0')
            NOT_DEF=$(echo "$CURRENT_RUN" | jq -r '.data["Not Defined"] // 0')
            TOTAL_RM=$((MATCH + MISMATCH + EXPECTED_NOT + NOT_DEF))
            if [ "$TOTAL_RM" -gt 0 ]; then
              MATCH_RATE=$(echo "scale=1; $MATCH * 100 / $TOTAL_RM" | bc)
              echo "| Status | Count |" >> $GITHUB_STEP_SUMMARY
              echo "|--------|-------|" >> $GITHUB_STEP_SUMMARY
              echo "| Rule Match | $MATCH |" >> $GITHUB_STEP_SUMMARY
              echo "| Rule Mismatch | $MISMATCH |" >> $GITHUB_STEP_SUMMARY
              echo "| Expected Not Detected | $EXPECTED_NOT |" >> $GITHUB_STEP_SUMMARY
              echo "| Not Defined | $NOT_DEF |" >> $GITHUB_STEP_SUMMARY
              echo "| **Match Rate** | **${MATCH_RATE}%** |" >> $GITHUB_STEP_SUMMARY
            fi
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
          echo "- [Test Results](../actions/runs/${{ github.run_id }})" >> $GITHUB_STEP_SUMMARY

          if [ "${{ github.ref }}" == "refs/heads/main" ] && [ "${{ github.event_name }}" != "pull_request" ]; then
            echo "- [Allure Report](https://takaosgb3.github.io/falco-plugin-nginx/e2e-report/${{ github.run_number }}/)" >> $GITHUB_STEP_SUMMARY
            echo "- [Rule Mapping Trend](https://takaosgb3.github.io/falco-plugin-nginx/e2e-report/${{ github.run_number }}/widgets/rule-mapping-trend.html)" >> $GITHUB_STEP_SUMMARY
            echo "- [Latest Report](https://takaosgb3.github.io/falco-plugin-nginx/e2e-report/latest/)" >> $GITHUB_STEP_SUMMARY
            if [ "${{ steps.download_history.outputs.history_available }}" == "true" ]; then
              echo "" >> $GITHUB_STEP_SUMMARY
              echo "*This report includes trend graphs from previous runs*" >> $GITHUB_STEP_SUMMARY
            fi
          fi

      # ========================================
      # 16. Cleanup
      # ========================================
      - name: Stop Falco
        if: always()
        run: |
          sudo pkill falco || true
          echo "Falco stopped"

      - name: Stop nginx
        if: always()
        run: |
          sudo systemctl stop nginx || true
          echo "nginx stopped"
